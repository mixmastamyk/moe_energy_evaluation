Active configuration: LARGE
Model parameters: Experts=16, Hidden Dim=1024, Layers=4, Top-K=4
Generating complex synthetic data...
Data generation complete.
Using device: cuda

--- Original MoE Model ---
 - Original MoE (Top-4) Architecture ---
MoE(
  (experts): ModuleList(
    (0-15): 16 x Expert(
      (net): Sequential(
        (0): Linear(in_features=784, out_features=1024, bias=True)
        (1): ReLU()
        (2): Linear(in_features=1024, out_features=1024, bias=True)
        (3): ReLU()
        (4): Linear(in_features=1024, out_features=1024, bias=True)
        (5): ReLU()
        (6): Linear(in_features=1024, out_features=1024, bias=True)
        (7): ReLU()
        (8): Linear(in_features=1024, out_features=10, bias=True)
      )
    )
  )
  (gating): Linear(in_features=784, out_features=16, bias=True)
)
--- Parameters ---
Layer: experts.0.net.0.weight, Parameters: 802816
Layer: experts.0.net.0.bias, Parameters: 1024
Layer: experts.0.net.2.weight, Parameters: 1048576
Layer: experts.0.net.2.bias, Parameters: 1024
Layer: experts.0.net.4.weight, Parameters: 1048576
Layer: experts.0.net.4.bias, Parameters: 1024
Layer: experts.0.net.6.weight, Parameters: 1048576
Layer: experts.0.net.6.bias, Parameters: 1024
Layer: experts.0.net.8.weight, Parameters: 10240
Layer: experts.0.net.8.bias, Parameters: 10
Layer: experts.1.net.0.weight, Parameters: 802816
Layer: experts.1.net.0.bias, Parameters: 1024
Layer: experts.1.net.2.weight, Parameters: 1048576
Layer: experts.1.net.2.bias, Parameters: 1024
Layer: experts.1.net.4.weight, Parameters: 1048576
Layer: experts.1.net.4.bias, Parameters: 1024
Layer: experts.1.net.6.weight, Parameters: 1048576
Layer: experts.1.net.6.bias, Parameters: 1024
Layer: experts.1.net.8.weight, Parameters: 10240
Layer: experts.1.net.8.bias, Parameters: 10
Layer: experts.2.net.0.weight, Parameters: 802816
Layer: experts.2.net.0.bias, Parameters: 1024
Layer: experts.2.net.2.weight, Parameters: 1048576
Layer: experts.2.net.2.bias, Parameters: 1024
Layer: experts.2.net.4.weight, Parameters: 1048576
Layer: experts.2.net.4.bias, Parameters: 1024
Layer: experts.2.net.6.weight, Parameters: 1048576
Layer: experts.2.net.6.bias, Parameters: 1024
Layer: experts.2.net.8.weight, Parameters: 10240
Layer: experts.2.net.8.bias, Parameters: 10
Layer: experts.3.net.0.weight, Parameters: 802816
Layer: experts.3.net.0.bias, Parameters: 1024
Layer: experts.3.net.2.weight, Parameters: 1048576
Layer: experts.3.net.2.bias, Parameters: 1024
Layer: experts.3.net.4.weight, Parameters: 1048576
Layer: experts.3.net.4.bias, Parameters: 1024
Layer: experts.3.net.6.weight, Parameters: 1048576
Layer: experts.3.net.6.bias, Parameters: 1024
Layer: experts.3.net.8.weight, Parameters: 10240
Layer: experts.3.net.8.bias, Parameters: 10
Layer: experts.4.net.0.weight, Parameters: 802816
Layer: experts.4.net.0.bias, Parameters: 1024
Layer: experts.4.net.2.weight, Parameters: 1048576
Layer: experts.4.net.2.bias, Parameters: 1024
Layer: experts.4.net.4.weight, Parameters: 1048576
Layer: experts.4.net.4.bias, Parameters: 1024
Layer: experts.4.net.6.weight, Parameters: 1048576
Layer: experts.4.net.6.bias, Parameters: 1024
Layer: experts.4.net.8.weight, Parameters: 10240
Layer: experts.4.net.8.bias, Parameters: 10
Layer: experts.5.net.0.weight, Parameters: 802816
Layer: experts.5.net.0.bias, Parameters: 1024
Layer: experts.5.net.2.weight, Parameters: 1048576
Layer: experts.5.net.2.bias, Parameters: 1024
Layer: experts.5.net.4.weight, Parameters: 1048576
Layer: experts.5.net.4.bias, Parameters: 1024
Layer: experts.5.net.6.weight, Parameters: 1048576
Layer: experts.5.net.6.bias, Parameters: 1024
Layer: experts.5.net.8.weight, Parameters: 10240
Layer: experts.5.net.8.bias, Parameters: 10
Layer: experts.6.net.0.weight, Parameters: 802816
Layer: experts.6.net.0.bias, Parameters: 1024
Layer: experts.6.net.2.weight, Parameters: 1048576
Layer: experts.6.net.2.bias, Parameters: 1024
Layer: experts.6.net.4.weight, Parameters: 1048576
Layer: experts.6.net.4.bias, Parameters: 1024
Layer: experts.6.net.6.weight, Parameters: 1048576
Layer: experts.6.net.6.bias, Parameters: 1024
Layer: experts.6.net.8.weight, Parameters: 10240
Layer: experts.6.net.8.bias, Parameters: 10
Layer: experts.7.net.0.weight, Parameters: 802816
Layer: experts.7.net.0.bias, Parameters: 1024
Layer: experts.7.net.2.weight, Parameters: 1048576
Layer: experts.7.net.2.bias, Parameters: 1024
Layer: experts.7.net.4.weight, Parameters: 1048576
Layer: experts.7.net.4.bias, Parameters: 1024
Layer: experts.7.net.6.weight, Parameters: 1048576
Layer: experts.7.net.6.bias, Parameters: 1024
Layer: experts.7.net.8.weight, Parameters: 10240
Layer: experts.7.net.8.bias, Parameters: 10
Layer: experts.8.net.0.weight, Parameters: 802816
Layer: experts.8.net.0.bias, Parameters: 1024
Layer: experts.8.net.2.weight, Parameters: 1048576
Layer: experts.8.net.2.bias, Parameters: 1024
Layer: experts.8.net.4.weight, Parameters: 1048576
Layer: experts.8.net.4.bias, Parameters: 1024
Layer: experts.8.net.6.weight, Parameters: 1048576
Layer: experts.8.net.6.bias, Parameters: 1024
Layer: experts.8.net.8.weight, Parameters: 10240
Layer: experts.8.net.8.bias, Parameters: 10
Layer: experts.9.net.0.weight, Parameters: 802816
Layer: experts.9.net.0.bias, Parameters: 1024
Layer: experts.9.net.2.weight, Parameters: 1048576
Layer: experts.9.net.2.bias, Parameters: 1024
Layer: experts.9.net.4.weight, Parameters: 1048576
Layer: experts.9.net.4.bias, Parameters: 1024
Layer: experts.9.net.6.weight, Parameters: 1048576
Layer: experts.9.net.6.bias, Parameters: 1024
Layer: experts.9.net.8.weight, Parameters: 10240
Layer: experts.9.net.8.bias, Parameters: 10
Layer: experts.10.net.0.weight, Parameters: 802816
Layer: experts.10.net.0.bias, Parameters: 1024
Layer: experts.10.net.2.weight, Parameters: 1048576
Layer: experts.10.net.2.bias, Parameters: 1024
Layer: experts.10.net.4.weight, Parameters: 1048576
Layer: experts.10.net.4.bias, Parameters: 1024
Layer: experts.10.net.6.weight, Parameters: 1048576
Layer: experts.10.net.6.bias, Parameters: 1024
Layer: experts.10.net.8.weight, Parameters: 10240
Layer: experts.10.net.8.bias, Parameters: 10
Layer: experts.11.net.0.weight, Parameters: 802816
Layer: experts.11.net.0.bias, Parameters: 1024
Layer: experts.11.net.2.weight, Parameters: 1048576
Layer: experts.11.net.2.bias, Parameters: 1024
Layer: experts.11.net.4.weight, Parameters: 1048576
Layer: experts.11.net.4.bias, Parameters: 1024
Layer: experts.11.net.6.weight, Parameters: 1048576
Layer: experts.11.net.6.bias, Parameters: 1024
Layer: experts.11.net.8.weight, Parameters: 10240
Layer: experts.11.net.8.bias, Parameters: 10
Layer: experts.12.net.0.weight, Parameters: 802816
Layer: experts.12.net.0.bias, Parameters: 1024
Layer: experts.12.net.2.weight, Parameters: 1048576
Layer: experts.12.net.2.bias, Parameters: 1024
Layer: experts.12.net.4.weight, Parameters: 1048576
Layer: experts.12.net.4.bias, Parameters: 1024
Layer: experts.12.net.6.weight, Parameters: 1048576
Layer: experts.12.net.6.bias, Parameters: 1024
Layer: experts.12.net.8.weight, Parameters: 10240
Layer: experts.12.net.8.bias, Parameters: 10
Layer: experts.13.net.0.weight, Parameters: 802816
Layer: experts.13.net.0.bias, Parameters: 1024
Layer: experts.13.net.2.weight, Parameters: 1048576
Layer: experts.13.net.2.bias, Parameters: 1024
Layer: experts.13.net.4.weight, Parameters: 1048576
Layer: experts.13.net.4.bias, Parameters: 1024
Layer: experts.13.net.6.weight, Parameters: 1048576
Layer: experts.13.net.6.bias, Parameters: 1024
Layer: experts.13.net.8.weight, Parameters: 10240
Layer: experts.13.net.8.bias, Parameters: 10
Layer: experts.14.net.0.weight, Parameters: 802816
Layer: experts.14.net.0.bias, Parameters: 1024
Layer: experts.14.net.2.weight, Parameters: 1048576
Layer: experts.14.net.2.bias, Parameters: 1024
Layer: experts.14.net.4.weight, Parameters: 1048576
Layer: experts.14.net.4.bias, Parameters: 1024
Layer: experts.14.net.6.weight, Parameters: 1048576
Layer: experts.14.net.6.bias, Parameters: 1024
Layer: experts.14.net.8.weight, Parameters: 10240
Layer: experts.14.net.8.bias, Parameters: 10
Layer: experts.15.net.0.weight, Parameters: 802816
Layer: experts.15.net.0.bias, Parameters: 1024
Layer: experts.15.net.2.weight, Parameters: 1048576
Layer: experts.15.net.2.bias, Parameters: 1024
Layer: experts.15.net.4.weight, Parameters: 1048576
Layer: experts.15.net.4.bias, Parameters: 1024
Layer: experts.15.net.6.weight, Parameters: 1048576
Layer: experts.15.net.6.bias, Parameters: 1024
Layer: experts.15.net.8.weight, Parameters: 10240
Layer: experts.15.net.8.bias, Parameters: 10
Layer: gating.weight, Parameters: 12544
Layer: gating.bias, Parameters: 16
Total Trainable Parameters: 63418800
--------------------------------------------

--- Optimized MoE Model ---
 - Optimized MoE (Top-4) Architecture ---
OptimizedMoE2(
  (experts): ModuleList(
    (0-15): 16 x Expert(
      (net): Sequential(
        (0): Linear(in_features=784, out_features=1024, bias=True)
        (1): ReLU()
        (2): Linear(in_features=1024, out_features=1024, bias=True)
        (3): ReLU()
        (4): Linear(in_features=1024, out_features=1024, bias=True)
        (5): ReLU()
        (6): Linear(in_features=1024, out_features=1024, bias=True)
        (7): ReLU()
        (8): Linear(in_features=1024, out_features=10, bias=True)
      )
    )
  )
  (gating): Linear(in_features=784, out_features=16, bias=True)
)
--- Parameters ---
Layer: experts.0.net.0.weight, Parameters: 802816
Layer: experts.0.net.0.bias, Parameters: 1024
Layer: experts.0.net.2.weight, Parameters: 1048576
Layer: experts.0.net.2.bias, Parameters: 1024
Layer: experts.0.net.4.weight, Parameters: 1048576
Layer: experts.0.net.4.bias, Parameters: 1024
Layer: experts.0.net.6.weight, Parameters: 1048576
Layer: experts.0.net.6.bias, Parameters: 1024
Layer: experts.0.net.8.weight, Parameters: 10240
Layer: experts.0.net.8.bias, Parameters: 10
Layer: experts.1.net.0.weight, Parameters: 802816
Layer: experts.1.net.0.bias, Parameters: 1024
Layer: experts.1.net.2.weight, Parameters: 1048576
Layer: experts.1.net.2.bias, Parameters: 1024
Layer: experts.1.net.4.weight, Parameters: 1048576
Layer: experts.1.net.4.bias, Parameters: 1024
Layer: experts.1.net.6.weight, Parameters: 1048576
Layer: experts.1.net.6.bias, Parameters: 1024
Layer: experts.1.net.8.weight, Parameters: 10240
Layer: experts.1.net.8.bias, Parameters: 10
Layer: experts.2.net.0.weight, Parameters: 802816
Layer: experts.2.net.0.bias, Parameters: 1024
Layer: experts.2.net.2.weight, Parameters: 1048576
Layer: experts.2.net.2.bias, Parameters: 1024
Layer: experts.2.net.4.weight, Parameters: 1048576
Layer: experts.2.net.4.bias, Parameters: 1024
Layer: experts.2.net.6.weight, Parameters: 1048576
Layer: experts.2.net.6.bias, Parameters: 1024
Layer: experts.2.net.8.weight, Parameters: 10240
Layer: experts.2.net.8.bias, Parameters: 10
Layer: experts.3.net.0.weight, Parameters: 802816
Layer: experts.3.net.0.bias, Parameters: 1024
Layer: experts.3.net.2.weight, Parameters: 1048576
Layer: experts.3.net.2.bias, Parameters: 1024
Layer: experts.3.net.4.weight, Parameters: 1048576
Layer: experts.3.net.4.bias, Parameters: 1024
Layer: experts.3.net.6.weight, Parameters: 1048576
Layer: experts.3.net.6.bias, Parameters: 1024
Layer: experts.3.net.8.weight, Parameters: 10240
Layer: experts.3.net.8.bias, Parameters: 10
Layer: experts.4.net.0.weight, Parameters: 802816
Layer: experts.4.net.0.bias, Parameters: 1024
Layer: experts.4.net.2.weight, Parameters: 1048576
Layer: experts.4.net.2.bias, Parameters: 1024
Layer: experts.4.net.4.weight, Parameters: 1048576
Layer: experts.4.net.4.bias, Parameters: 1024
Layer: experts.4.net.6.weight, Parameters: 1048576
Layer: experts.4.net.6.bias, Parameters: 1024
Layer: experts.4.net.8.weight, Parameters: 10240
Layer: experts.4.net.8.bias, Parameters: 10
Layer: experts.5.net.0.weight, Parameters: 802816
Layer: experts.5.net.0.bias, Parameters: 1024
Layer: experts.5.net.2.weight, Parameters: 1048576
Layer: experts.5.net.2.bias, Parameters: 1024
Layer: experts.5.net.4.weight, Parameters: 1048576
Layer: experts.5.net.4.bias, Parameters: 1024
Layer: experts.5.net.6.weight, Parameters: 1048576
Layer: experts.5.net.6.bias, Parameters: 1024
Layer: experts.5.net.8.weight, Parameters: 10240
Layer: experts.5.net.8.bias, Parameters: 10
Layer: experts.6.net.0.weight, Parameters: 802816
Layer: experts.6.net.0.bias, Parameters: 1024
Layer: experts.6.net.2.weight, Parameters: 1048576
Layer: experts.6.net.2.bias, Parameters: 1024
Layer: experts.6.net.4.weight, Parameters: 1048576
Layer: experts.6.net.4.bias, Parameters: 1024
Layer: experts.6.net.6.weight, Parameters: 1048576
Layer: experts.6.net.6.bias, Parameters: 1024
Layer: experts.6.net.8.weight, Parameters: 10240
Layer: experts.6.net.8.bias, Parameters: 10
Layer: experts.7.net.0.weight, Parameters: 802816
Layer: experts.7.net.0.bias, Parameters: 1024
Layer: experts.7.net.2.weight, Parameters: 1048576
Layer: experts.7.net.2.bias, Parameters: 1024
Layer: experts.7.net.4.weight, Parameters: 1048576
Layer: experts.7.net.4.bias, Parameters: 1024
Layer: experts.7.net.6.weight, Parameters: 1048576
Layer: experts.7.net.6.bias, Parameters: 1024
Layer: experts.7.net.8.weight, Parameters: 10240
Layer: experts.7.net.8.bias, Parameters: 10
Layer: experts.8.net.0.weight, Parameters: 802816
Layer: experts.8.net.0.bias, Parameters: 1024
Layer: experts.8.net.2.weight, Parameters: 1048576
Layer: experts.8.net.2.bias, Parameters: 1024
Layer: experts.8.net.4.weight, Parameters: 1048576
Layer: experts.8.net.4.bias, Parameters: 1024
Layer: experts.8.net.6.weight, Parameters: 1048576
Layer: experts.8.net.6.bias, Parameters: 1024
Layer: experts.8.net.8.weight, Parameters: 10240
Layer: experts.8.net.8.bias, Parameters: 10
Layer: experts.9.net.0.weight, Parameters: 802816
Layer: experts.9.net.0.bias, Parameters: 1024
Layer: experts.9.net.2.weight, Parameters: 1048576
Layer: experts.9.net.2.bias, Parameters: 1024
Layer: experts.9.net.4.weight, Parameters: 1048576
Layer: experts.9.net.4.bias, Parameters: 1024
Layer: experts.9.net.6.weight, Parameters: 1048576
Layer: experts.9.net.6.bias, Parameters: 1024
Layer: experts.9.net.8.weight, Parameters: 10240
Layer: experts.9.net.8.bias, Parameters: 10
Layer: experts.10.net.0.weight, Parameters: 802816
Layer: experts.10.net.0.bias, Parameters: 1024
Layer: experts.10.net.2.weight, Parameters: 1048576
Layer: experts.10.net.2.bias, Parameters: 1024
Layer: experts.10.net.4.weight, Parameters: 1048576
Layer: experts.10.net.4.bias, Parameters: 1024
Layer: experts.10.net.6.weight, Parameters: 1048576
Layer: experts.10.net.6.bias, Parameters: 1024
Layer: experts.10.net.8.weight, Parameters: 10240
Layer: experts.10.net.8.bias, Parameters: 10
Layer: experts.11.net.0.weight, Parameters: 802816
Layer: experts.11.net.0.bias, Parameters: 1024
Layer: experts.11.net.2.weight, Parameters: 1048576
Layer: experts.11.net.2.bias, Parameters: 1024
Layer: experts.11.net.4.weight, Parameters: 1048576
Layer: experts.11.net.4.bias, Parameters: 1024
Layer: experts.11.net.6.weight, Parameters: 1048576
Layer: experts.11.net.6.bias, Parameters: 1024
Layer: experts.11.net.8.weight, Parameters: 10240
Layer: experts.11.net.8.bias, Parameters: 10
Layer: experts.12.net.0.weight, Parameters: 802816
Layer: experts.12.net.0.bias, Parameters: 1024
Layer: experts.12.net.2.weight, Parameters: 1048576
Layer: experts.12.net.2.bias, Parameters: 1024
Layer: experts.12.net.4.weight, Parameters: 1048576
Layer: experts.12.net.4.bias, Parameters: 1024
Layer: experts.12.net.6.weight, Parameters: 1048576
Layer: experts.12.net.6.bias, Parameters: 1024
Layer: experts.12.net.8.weight, Parameters: 10240
Layer: experts.12.net.8.bias, Parameters: 10
Layer: experts.13.net.0.weight, Parameters: 802816
Layer: experts.13.net.0.bias, Parameters: 1024
Layer: experts.13.net.2.weight, Parameters: 1048576
Layer: experts.13.net.2.bias, Parameters: 1024
Layer: experts.13.net.4.weight, Parameters: 1048576
Layer: experts.13.net.4.bias, Parameters: 1024
Layer: experts.13.net.6.weight, Parameters: 1048576
Layer: experts.13.net.6.bias, Parameters: 1024
Layer: experts.13.net.8.weight, Parameters: 10240
Layer: experts.13.net.8.bias, Parameters: 10
Layer: experts.14.net.0.weight, Parameters: 802816
Layer: experts.14.net.0.bias, Parameters: 1024
Layer: experts.14.net.2.weight, Parameters: 1048576
Layer: experts.14.net.2.bias, Parameters: 1024
Layer: experts.14.net.4.weight, Parameters: 1048576
Layer: experts.14.net.4.bias, Parameters: 1024
Layer: experts.14.net.6.weight, Parameters: 1048576
Layer: experts.14.net.6.bias, Parameters: 1024
Layer: experts.14.net.8.weight, Parameters: 10240
Layer: experts.14.net.8.bias, Parameters: 10
Layer: experts.15.net.0.weight, Parameters: 802816
Layer: experts.15.net.0.bias, Parameters: 1024
Layer: experts.15.net.2.weight, Parameters: 1048576
Layer: experts.15.net.2.bias, Parameters: 1024
Layer: experts.15.net.4.weight, Parameters: 1048576
Layer: experts.15.net.4.bias, Parameters: 1024
Layer: experts.15.net.6.weight, Parameters: 1048576
Layer: experts.15.net.6.bias, Parameters: 1024
Layer: experts.15.net.8.weight, Parameters: 10240
Layer: experts.15.net.8.bias, Parameters: 10
Layer: gating.weight, Parameters: 12544
Layer: gating.bias, Parameters: 16
Total Trainable Parameters: 63418800
---------------------------------------------

Training Original MoE model for 15 epochs...
Epoch 1/15, Loss: 2.2928, Accuracy: 12.96%
Epoch 2/15, Loss: 1.9663, Accuracy: 29.84%
Epoch 3/15, Loss: 1.3053, Accuracy: 54.90%
Epoch 4/15, Loss: 0.7056, Accuracy: 75.93%
Epoch 5/15, Loss: 0.4428, Accuracy: 85.92%
Epoch 6/15, Loss: 0.3247, Accuracy: 90.17%
Epoch 7/15, Loss: 0.2321, Accuracy: 92.89%
Epoch 8/15, Loss: 0.2207, Accuracy: 93.64%
Epoch 9/15, Loss: 0.1857, Accuracy: 94.79%
Epoch 10/15, Loss: 0.1411, Accuracy: 95.78%
Epoch 11/15, Loss: 0.1693, Accuracy: 95.28%
Epoch 12/15, Loss: 0.2126, Accuracy: 94.47%
Epoch 13/15, Loss: 0.2001, Accuracy: 94.61%
Epoch 14/15, Loss: 0.1594, Accuracy: 95.99%
Epoch 15/15, Loss: 0.1124, Accuracy: 97.11%

Training Optimized MoE model for 15 epochs...
Epoch 1/15, Loss: 2.2964, Accuracy: 12.53%
Epoch 2/15, Loss: 2.0102, Accuracy: 28.95%
Epoch 3/15, Loss: 1.3134, Accuracy: 54.38%
Epoch 4/15, Loss: 0.6770, Accuracy: 77.80%
Epoch 5/15, Loss: 0.3874, Accuracy: 87.75%
Epoch 6/15, Loss: 0.2958, Accuracy: 90.85%
Epoch 7/15, Loss: 0.1879, Accuracy: 94.30%
Epoch 8/15, Loss: 0.1883, Accuracy: 94.47%
Epoch 9/15, Loss: 0.2047, Accuracy: 94.20%
Epoch 10/15, Loss: 0.1687, Accuracy: 95.42%
Epoch 11/15, Loss: 0.1703, Accuracy: 95.47%
Epoch 12/15, Loss: 0.1583, Accuracy: 95.49%
Epoch 13/15, Loss: 0.2153, Accuracy: 94.20%
Epoch 14/15, Loss: 0.1730, Accuracy: 95.24%
Epoch 15/15, Loss: 0.1473, Accuracy: 96.50%

Target Baseline Params (1 Expert + Gating): 63418800
Using Baseline Config: Num Layers=4
Calculated Baseline Hidden Dimension (Approx): 4467
 - Baseline Model Architecture ---
BaselineMLP(
  (net): Sequential(
    (0): Linear(in_features=784, out_features=4467, bias=True)
    (1): ReLU()
    (2): Linear(in_features=4467, out_features=4467, bias=True)
    (3): ReLU()
    (4): Linear(in_features=4467, out_features=4467, bias=True)
    (5): ReLU()
    (6): Linear(in_features=4467, out_features=4467, bias=True)
    (7): ReLU()
    (8): Linear(in_features=4467, out_features=10, bias=True)
  )
)
--- Parameters ---
Layer: net.0.weight, Parameters: 3502128
Layer: net.0.bias, Parameters: 4467
Layer: net.2.weight, Parameters: 19954089
Layer: net.2.bias, Parameters: 4467
Layer: net.4.weight, Parameters: 19954089
Layer: net.4.bias, Parameters: 4467
Layer: net.6.weight, Parameters: 19954089
Layer: net.6.bias, Parameters: 4467
Layer: net.8.weight, Parameters: 44670
Layer: net.8.bias, Parameters: 10
Total Trainable Parameters: 63426943
--------------------------------------
Target Baseline Params: 63418800, Actual Baseline Params: 63426943

Training Baseline model for 15 epochs...
Epoch 1/15, Loss: 2.3648, Accuracy: 11.74%
Epoch 2/15, Loss: 2.1605, Accuracy: 20.82%
Epoch 3/15, Loss: 1.7911, Accuracy: 36.68%
Epoch 4/15, Loss: 1.2364, Accuracy: 57.64%
Epoch 5/15, Loss: 0.7459, Accuracy: 75.31%
Epoch 6/15, Loss: 0.4395, Accuracy: 85.69%
Epoch 7/15, Loss: 0.2428, Accuracy: 92.23%
Epoch 8/15, Loss: 0.2001, Accuracy: 93.50%
Epoch 9/15, Loss: 0.1398, Accuracy: 95.41%
Epoch 10/15, Loss: 0.0960, Accuracy: 97.07%
Epoch 11/15, Loss: 0.0987, Accuracy: 96.94%
Epoch 12/15, Loss: 0.1042, Accuracy: 96.52%
Epoch 13/15, Loss: 0.0787, Accuracy: 97.43%
Epoch 14/15, Loss: 0.0644, Accuracy: 98.17%
Epoch 15/15, Loss: 0.1130, Accuracy: 96.56%

--- Original MoE Inference Timing ---
Starting inference timing for 30 seconds...
Start Time: 2025-04-22 01:55:13
NVML initialized for GPU 0.
NVML shut down.
End Time:   2025-04-22 01:55:43
Actual Duration: 30.0020 seconds
Total Inferences: 758656
Inferences per Second: 25286.84
Total Energy Consumed: 2989.60 Joules
Average Power: 99.65 Watts
Original MoE Total Trainable Parameters: 63418800

--- Optimized MoE Inference Timing ---
Starting inference timing for 30 seconds...
Start Time: 2025-04-22 01:55:43
NVML initialized for GPU 0.
NVML shut down.
End Time:   2025-04-22 01:56:13
Actual Duration: 30.0005 seconds
Total Inferences: 773120
Inferences per Second: 25770.22
Total Energy Consumed: 2942.07 Joules
Average Power: 98.07 Watts
Optimized MoE Total Trainable Parameters: 63418800

--- Baseline Inference Timing ---
Starting inference timing for 30 seconds...
Start Time: 2025-04-22 01:56:13
NVML initialized for GPU 0.
NVML shut down.
End Time:   2025-04-22 01:56:43
Actual Duration: 30.0002 seconds
Total Inferences: 2727424
Inferences per Second: 90913.55
Total Energy Consumed: 8116.01 Joules
Average Power: 270.53 Watts
Baseline Total Trainable Parameters: 63426943

--- Final Accuracy Comparison ---
Original MoE Final Accuracy: 98.05%
Optimized MoE Final Accuracy: 97.63%
Baseline Final Accuracy: 98.32%

--- Summary ---
Timing Results (Inferences per Second):
- Original MoE: 25286.84
- Optimized MoE: 25770.22
- Baseline: 90913.55

Accuracy Results:
- Original MoE: 98.05%
- Optimized MoE: 97.63%
- Baseline: 98.32%

Energy Efficiency Results (Inferences per Joule):
- Original MoE: 253.76 inferences/Joule
- Optimized MoE: 262.78 inferences/Joule
- Baseline: 336.05 inferences/Joule
